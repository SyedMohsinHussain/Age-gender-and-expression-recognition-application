{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 234911,
          "sourceType": "datasetVersion",
          "datasetId": 99505
        }
      ],
      "dockerImageVersionId": 30840,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "5QR96ZVgdwZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from PIL import Image"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-03T06:41:08.872649Z",
          "iopub.execute_input": "2025-02-03T06:41:08.873026Z",
          "iopub.status.idle": "2025-02-03T06:41:08.877845Z",
          "shell.execute_reply.started": "2025-02-03T06:41:08.872990Z",
          "shell.execute_reply": "2025-02-03T06:41:08.876883Z"
        },
        "id": "ef3Jie9mdwZS"
      },
      "outputs": [],
      "execution_count": 44
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define image size and age bins"
      ],
      "metadata": {
        "id": "ddiFgTeljeqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = (128, 128)\n",
        "AGE_BINS = [0, 12, 20, 30, 60, 100]\n",
        "AGE_LABELS = ['Child', 'Teen', 'Young Adult', 'Adult', 'Elderly']\n",
        "GENDER_LABELS = ['Male', 'Female']"
      ],
      "metadata": {
        "id": "OwGjQTDVjgW6"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Preprocessing\n"
      ],
      "metadata": {
        "id": "nNwK6AaMdwZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rP01YVYecKt",
        "outputId": "7e06cd71-4a6f-4dd0-ac9e-878dff166ab7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define paths\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "zip_path_expr = '/content/drive/MyDrive/Face expression.zip'\n",
        "expr_dir = '/content/face-expression-recognition-dataset'\n",
        "\n",
        "zip_path_utk = '/content/drive/MyDrive/UTKFace.zip'\n",
        "utkface_dir = '/content/UTKFace'\n",
        "\n",
        "# Extract the Face Expression dataset\n",
        "with zipfile.ZipFile(zip_path_expr, 'r') as zip_ref:\n",
        "    zip_ref.extractall(expr_dir)\n",
        "print(\"Face Expression dataset extracted successfully.\")\n",
        "\n",
        "# Extract the UTKFace dataset\n",
        "with zipfile.ZipFile(zip_path_utk, 'r') as zip_ref:\n",
        "    zip_ref.extractall(utkface_dir)\n",
        "print(\"UTKFace dataset extracted successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cNLEU8AkU7j",
        "outputId": "8f343167-e97e-463d-8065-9de6756be899"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Face Expression dataset extracted successfully.\n",
            "UTKFace dataset extracted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "expr_train_path = '/content/face-expression-recognition-dataset/images/train'\n",
        "expr_val_path = '/content/face-expression-recognition-dataset/images/validation'\n",
        "utk_path = '/content/UTKFace/utkface_aligned_cropped/crop_part1'"
      ],
      "metadata": {
        "id": "sZpHCnX3oMmH"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## create dataframe"
      ],
      "metadata": {
        "id": "zbgKB9G2jix4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_utkface_metadata(folder_path):\n",
        "    ages, genders, image_paths = [], [], []\n",
        "    for fname in os.listdir(folder_path):\n",
        "        try:\n",
        "            split = fname.split('_')\n",
        "            ages.append(int(split[0]))\n",
        "            genders.append(int(split[1]))\n",
        "            image_paths.append(os.path.join(folder_path, fname))\n",
        "        except:\n",
        "            continue\n",
        "    df = pd.DataFrame({\n",
        "        'path': image_paths,\n",
        "        'age': ages,\n",
        "        'gender': genders\n",
        "    })\n",
        "    df['age_group'] = pd.cut(df['age'], bins=AGE_BINS, labels=AGE_LABELS, right=False)\n",
        "    df['gender_label'] = df['gender'].map({0: 'Male', 1: 'Female'})\n",
        "    return df"
      ],
      "metadata": {
        "id": "pYqXGF3CjiiQ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load FER expression data and create dataframe"
      ],
      "metadata": {
        "id": "kDzxXRBHjmLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_expression_data(base_dir):\n",
        "    data = []\n",
        "    label_map = {}\n",
        "    for i, emotion in enumerate(sorted(os.listdir(base_dir))):\n",
        "        emotion_dir = os.path.join(base_dir, emotion)\n",
        "        if not os.path.isdir(emotion_dir):\n",
        "            continue\n",
        "        label_map[emotion] = i\n",
        "        for fname in os.listdir(emotion_dir):\n",
        "            path = os.path.join(emotion_dir, fname)\n",
        "            if os.path.isfile(path):\n",
        "                data.append({'path': path, 'expression': emotion})\n",
        "    df = pd.DataFrame(data)\n",
        "    return df, label_map\n"
      ],
      "metadata": {
        "id": "jm9KYyEcjoRO"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and preprocess images"
      ],
      "metadata": {
        "id": "-f_B5oKgjpRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_df(df, label_column, image_size):\n",
        "    images, labels = [], []\n",
        "    for _, row in df.iterrows():\n",
        "        img_path = row['path']\n",
        "        if not os.path.isfile(img_path):\n",
        "            print(f\"Skipped (not a file): {img_path}\")\n",
        "            continue\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            print(f\"Skipped (not an image or corrupted): {img_path}\")\n",
        "            continue\n",
        "        img = cv2.resize(img, image_size)\n",
        "        images.append(img)\n",
        "        labels.append(row[label_column])\n",
        "    return np.array(images), labels\n"
      ],
      "metadata": {
        "id": "Ur1Y_BtNjqlo"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create metadata and load images"
      ],
      "metadata": {
        "id": "d6Z_AGkxj320"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "utk_df = parse_utkface_metadata(utk_path)\n",
        "expr_train_df, expr_map = load_expression_data(expr_train_path)\n",
        "expr_val_df, _ = load_expression_data(expr_val_path)"
      ],
      "metadata": {
        "id": "z8jEM-gQoYU4"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "utk_imgs, utk_age_labels = load_images_from_df(utk_df, 'age_group', IMAGE_SIZE)\n",
        "_, utk_gender_labels = load_images_from_df(utk_df, 'gender_label', IMAGE_SIZE)\n",
        "\n",
        "expr_train_imgs, expr_train_labels = load_images_from_df(expr_train_df, 'expression', IMAGE_SIZE)\n",
        "expr_val_imgs, expr_val_labels = load_images_from_df(expr_val_df, 'expression', IMAGE_SIZE)"
      ],
      "metadata": {
        "id": "3AGphVNzj5sk"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess and encode labels"
      ],
      "metadata": {
        "id": "RbOWqpEjj6sX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le_age = LabelEncoder()\n",
        "le_gender = LabelEncoder()\n",
        "le_expr = LabelEncoder()\n",
        "\n",
        "age_encoded = to_categorical(le_age.fit_transform(utk_age_labels))\n",
        "gender_encoded = to_categorical(le_gender.fit_transform(utk_gender_labels))\n",
        "expr_train_encoded = to_categorical(le_expr.fit_transform(expr_train_labels))\n",
        "expr_val_encoded = to_categorical(le_expr.transform(expr_val_labels))\n",
        "\n",
        "# Normalize pixel values\n",
        "utk_imgs = utk_imgs.astype('float32') / 255.0\n",
        "expr_train_imgs = expr_train_imgs.astype('float32') / 255.0\n",
        "expr_val_imgs = expr_val_imgs.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "PgNCeI6lj8K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split datasets"
      ],
      "metadata": {
        "id": "P9AqF3sVj9Vp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_age_train, X_age_test, y_age_train, y_age_test = train_test_split(\n",
        "    utk_imgs, age_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "X_gender_train, X_gender_test, y_gender_train, y_gender_test = train_test_split(\n",
        "    utk_imgs, gender_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "X_expr_train, X_expr_test, y_expr_train, y_expr_test = train_test_split(\n",
        "    expr_train_imgs, expr_train_encoded, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "h3CN4Yoqj-yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Multi-Output CNN Model"
      ],
      "metadata": {
        "id": "utKspeb9j_q0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = Input(shape=(128, 128, 3))\n",
        "base_model = MobileNetV2(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# Age prediction head\n",
        "age_head = Dense(64, activation='relu')(x)\n",
        "age_output = Dense(len(AGE_LABELS), activation='softmax', name='age')(age_head)\n",
        "\n",
        "# Gender prediction head\n",
        "gender_head = Dense(64, activation='relu')(x)\n",
        "gender_output = Dense(len(GENDER_LABELS), activation='softmax', name='gender')(gender_head)\n",
        "\n",
        "# Expression prediction head\n",
        "expr_head = Dense(64, activation='relu')(x)\n",
        "expr_output = Dense(len(expr_map), activation='softmax', name='expression')(expr_head)\n",
        "\n",
        "# Combine into model\n",
        "multi_model = Model(inputs=input_tensor, outputs=[age_output, gender_output, expr_output])\n",
        "\n",
        "multi_model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss={\n",
        "        'age': 'categorical_crossentropy',\n",
        "        'gender': 'categorical_crossentropy',\n",
        "        'expression': 'categorical_crossentropy'\n",
        "    },\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "multi_model.summary()"
      ],
      "metadata": {
        "id": "Y2rL8chpkBOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model separately on tasks"
      ],
      "metadata": {
        "id": "Kn8o5BsYkCPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multi_model.fit(\n",
        "    X_age_train,\n",
        "    {'age': y_age_train, 'gender': np.zeros_like(y_gender_train), 'expression': np.zeros_like(y_expr_train)},\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Train on Gender only\n",
        "multi_model.fit(\n",
        "    X_gender_train,\n",
        "    {'age': np.zeros_like(y_age_train), 'gender': y_gender_train, 'expression': np.zeros_like(y_expr_train)},\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Train on Expression only\n",
        "multi_model.fit(\n",
        "    X_expr_train,\n",
        "    {'age': np.zeros_like(y_age_train), 'gender': np.zeros_like(y_gender_train), 'expression': y_expr_train},\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "id": "tAQgBw8ekDx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save and convert to TFLite"
      ],
      "metadata": {
        "id": "Tkwk3HCXkEy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multi_model.save(\"age_gender_expression_model.h5\")\n",
        "print(\"Keras model saved as 'age_gender_expression_model.h5'\")"
      ],
      "metadata": {
        "id": "nSeLIx_jkGEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(multi_model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(\"age_gender_expression_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"TFLite model exported as 'age_gender_expression_model.tflite'\")"
      ],
      "metadata": {
        "id": "a9C-xHgEo2uN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}